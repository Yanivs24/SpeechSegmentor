	train_epoch_loss	dev_epoch_loss	dev_precision	dev_recall	dev_f1
0	0.039343287646770475	0.010921409043172995	0.7391303544423528	0.7391303544423528	0.739125354476176
1	0.016350788343697787	0.006044202328970035	0.8369564307656053	0.8369564307656053	0.8369514307954753
2	0.013289882941171527	0.005851120532800754	0.7608694825141866	0.7608694825141866	0.7608644825470435
3	0.01400509174913168	0.007525883925457795	0.7826086105860206	0.7826086105860206	0.7826036106179648
4	0.011683623567223548	0.005875325140853723	0.8260868667296883	0.8260868667296883	0.8260818667599512
5	0.01061882168520242	0.009274517030765613	0.8369564307656053	0.8369564307656053	0.8369514307954753
6	0.011028466382995247	0.006844001356512308	0.8043477386578545	0.8043477386578545	0.8043427386889352
7	0.009115053992718457	0.00588449106241266	0.7608694825141866	0.7608694825141866	0.7608644825470435
8	0.01046086085960269	0.007902900377909342	0.7826086105860206	0.7826086105860206	0.7826036106179648
9	0.00823453496210277	0.009040774467090765	0.7934781746219375	0.7934781746219375	0.793473174653444
10	0.008145970422774554	0.009392944940676292	0.8043477386578545	0.8043477386578545	0.8043427386889352
11	0.007166458098217845	0.011521143528322378	0.7608694825141866	0.7499999184782697	0.7553906016368972
12	0.007306802179664373	0.008683064176390568	0.7608694825141866	0.7608694825141866	0.7608644825470435
